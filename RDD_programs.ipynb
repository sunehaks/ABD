{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDD programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tCreate RDDs in three different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "Spark = SparkSession.builder.appName('RDD_programs').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) From local collection using parallelise method of spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'just', 'my', 'collection', 'of', 'words']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCollection = \"This is just my collection of words\".split(\" \")\n",
    "#Spark.sparkContext.broadcast()\n",
    "words = Spark.sparkContext.parallelize(myCollection, 2)\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) From data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Category',\n",
       "  'State/ UT Name',\n",
       "  'Cow Milk-2010-11',\n",
       "  'Cow Milk-2011-12',\n",
       "  'Cow Milk-2013-14',\n",
       "  'Cow Milk-2014-15',\n",
       "  'Cow Milk-2015-16',\n",
       "  'Boffalo Milk-2010-11',\n",
       "  'Boffalo Milk-2011-12',\n",
       "  'Boffalo Milk-2013-14',\n",
       "  'Boffalo Milk-2014-15',\n",
       "  'Boffalo Milk-2015-16',\n",
       "  'Goat Milk-2010-11',\n",
       "  'Goat Milk-2011-12',\n",
       "  'Goat Milk-2013-14',\n",
       "  'Goat Milk-2014-15',\n",
       "  'Goat Milk-2015-16'],\n",
       " ['State',\n",
       "  'Andhra Pradesh',\n",
       "  '3102',\n",
       "  '3377',\n",
       "  '3799',\n",
       "  '3079',\n",
       "  '3369',\n",
       "  '8101',\n",
       "  '8710',\n",
       "  '9207',\n",
       "  '6574',\n",
       "  '7445',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '3',\n",
       "  '3']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_datasource = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/milk_production.csv\",minPartitions=4).map(lambda ele : ele.split(\",\"))\n",
    "rdd_datasource.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) RDD from another RDD through transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first rdd\n",
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "rdd2 = rdd1.filter(lambda x: x.startswith('T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'The', 'The', 'The', 'The', 'There']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRead a text file and count the number of words in the file using RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a text file\n",
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "rdd1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tWrite a program to find the word frequency in a given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 7),\n",
       " ('just', 1),\n",
       " ('file.', 1),\n",
       " ('The', 4),\n",
       " ('in', 5),\n",
       " ('English', 3),\n",
       " ('are', 3),\n",
       " ('indefinite', 2),\n",
       " ('an.', 1),\n",
       " ('used', 3)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a text file\n",
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "#Mapping words\n",
    "rdd_map = rdd1.map(lambda x: (x,1))\n",
    "rdd_map.reduceByKey(lambda a,b: a+b).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWrite a program to convert all words in a file to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a text file\n",
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "upper_rdd = rdd1.map(lambda word: word.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THIS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'A',\n",
       " 'TESTING',\n",
       " 'TEXT',\n",
       " 'FILE.',\n",
       " 'THE',\n",
       " 'ARTICLES',\n",
       " 'IN',\n",
       " 'ENGLISH',\n",
       " 'ARE',\n",
       " 'THE',\n",
       " 'DEFINITE',\n",
       " 'ARTICLE',\n",
       " 'THE',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'INDEFINITE',\n",
       " 'ARTICLES',\n",
       " 'A',\n",
       " 'AND',\n",
       " 'AN.',\n",
       " 'THE',\n",
       " 'DEFINITE',\n",
       " 'ARTICLE',\n",
       " 'IS',\n",
       " 'USED',\n",
       " 'WHEN',\n",
       " 'THE',\n",
       " 'SPEAKER',\n",
       " 'BELIEVES',\n",
       " 'THAT',\n",
       " 'THE',\n",
       " 'LISTENER',\n",
       " 'KNOWS',\n",
       " 'THE',\n",
       " 'IDENTITY',\n",
       " 'OF',\n",
       " 'THE',\n",
       " \"NOUN'S\",\n",
       " 'REFERENT',\n",
       " '(BECAUSE',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'OBVIOUS,',\n",
       " 'BECAUSE',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'COMMON',\n",
       " 'KNOWLEDGE,',\n",
       " 'OR',\n",
       " 'BECAUSE',\n",
       " 'IT',\n",
       " 'WAS',\n",
       " 'MENTIONED',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SAME',\n",
       " 'SENTENCE',\n",
       " 'OR',\n",
       " 'AN',\n",
       " 'EARLIER',\n",
       " 'SENTENCE).',\n",
       " 'THE',\n",
       " 'INDEFINITE',\n",
       " 'ARTICLE',\n",
       " 'IS',\n",
       " 'USED',\n",
       " 'WHEN',\n",
       " 'THE',\n",
       " 'SPEAKER',\n",
       " 'BELIEVES',\n",
       " 'THAT',\n",
       " 'THE',\n",
       " 'LISTENER',\n",
       " 'DOES',\n",
       " 'NOT',\n",
       " 'HAVE',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'TOLD',\n",
       " 'THE',\n",
       " 'IDENTITY',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'REFERENT.',\n",
       " 'NO',\n",
       " 'ARTICLE',\n",
       " 'IS',\n",
       " 'USED',\n",
       " 'IN',\n",
       " 'SOME',\n",
       " 'NOUN',\n",
       " 'PHRASES.',\n",
       " '',\n",
       " 'ENGLISH',\n",
       " 'GRAMMAR',\n",
       " 'REQUIRES',\n",
       " 'THAT',\n",
       " 'IN',\n",
       " 'MOST',\n",
       " 'CASES',\n",
       " 'A',\n",
       " 'NOUN',\n",
       " 'PHRASE',\n",
       " 'START',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'DETERMINER.',\n",
       " 'THE',\n",
       " 'MOST',\n",
       " 'COMMON',\n",
       " 'DETERMINERS',\n",
       " 'ARE',\n",
       " 'THE',\n",
       " 'ARTICLES',\n",
       " 'THE',\n",
       " 'AND',\n",
       " 'A(N),',\n",
       " 'WHICH',\n",
       " 'SPECIFY',\n",
       " 'THE',\n",
       " 'PRESENCE',\n",
       " 'OR',\n",
       " 'ABSENCE',\n",
       " 'OF',\n",
       " 'DEFINITENESS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'NOUN.',\n",
       " 'OTHER',\n",
       " 'POSSIBLE',\n",
       " 'DETERMINERS',\n",
       " 'INCLUDE',\n",
       " 'WORDS',\n",
       " 'LIKE',\n",
       " 'THIS,',\n",
       " 'MY,',\n",
       " 'EACH',\n",
       " 'AND',\n",
       " 'MANY',\n",
       " 'SEE',\n",
       " 'ENGLISH',\n",
       " 'DETERMINERS.',\n",
       " 'THERE',\n",
       " 'ARE',\n",
       " 'ALSO',\n",
       " 'CASES',\n",
       " 'WHERE',\n",
       " 'NO',\n",
       " 'DETERMINER',\n",
       " 'IS',\n",
       " 'REQUIRED,',\n",
       " 'AS',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SENTENCE',\n",
       " 'JOHN',\n",
       " 'LIKES',\n",
       " 'FAST',\n",
       " 'CARS,',\n",
       " 'WHERE',\n",
       " 'NEITHER',\n",
       " 'JOHN',\n",
       " 'NOR',\n",
       " 'FAST',\n",
       " 'CARS',\n",
       " 'INCLUDES',\n",
       " 'A',\n",
       " 'DETERMINER.',\n",
       " '']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_rdd.saveAsTextFile(\"C:/Users/Dell/Downloads/upper_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THIS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'A',\n",
       " 'TESTING',\n",
       " 'TEXT',\n",
       " 'FILE.',\n",
       " 'THE',\n",
       " 'ARTICLES',\n",
       " 'IN',\n",
       " 'ENGLISH',\n",
       " 'ARE',\n",
       " 'THE',\n",
       " 'DEFINITE',\n",
       " 'ARTICLE',\n",
       " 'THE',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'INDEFINITE',\n",
       " 'ARTICLES',\n",
       " 'A',\n",
       " 'AND',\n",
       " 'AN.',\n",
       " 'THE',\n",
       " 'DEFINITE',\n",
       " 'ARTICLE',\n",
       " 'IS',\n",
       " 'USED',\n",
       " 'WHEN',\n",
       " 'THE',\n",
       " 'SPEAKER',\n",
       " 'BELIEVES',\n",
       " 'THAT',\n",
       " 'THE',\n",
       " 'LISTENER',\n",
       " 'KNOWS',\n",
       " 'THE',\n",
       " 'IDENTITY',\n",
       " 'OF',\n",
       " 'THE',\n",
       " \"NOUN'S\",\n",
       " 'REFERENT',\n",
       " '(BECAUSE',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'OBVIOUS,',\n",
       " 'BECAUSE',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'COMMON',\n",
       " 'KNOWLEDGE,',\n",
       " 'OR',\n",
       " 'BECAUSE',\n",
       " 'IT',\n",
       " 'WAS',\n",
       " 'MENTIONED',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SAME',\n",
       " 'SENTENCE',\n",
       " 'OR',\n",
       " 'AN',\n",
       " 'EARLIER',\n",
       " 'SENTENCE).',\n",
       " 'THE',\n",
       " 'INDEFINITE',\n",
       " 'ARTICLE',\n",
       " 'IS',\n",
       " 'USED',\n",
       " 'WHEN',\n",
       " 'THE',\n",
       " 'SPEAKER',\n",
       " 'BELIEVES',\n",
       " 'THAT',\n",
       " 'THE',\n",
       " 'LISTENER',\n",
       " 'DOES',\n",
       " 'NOT',\n",
       " 'HAVE',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'TOLD',\n",
       " 'THE',\n",
       " 'IDENTITY',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'REFERENT.',\n",
       " 'NO',\n",
       " 'ARTICLE',\n",
       " 'IS',\n",
       " 'USED',\n",
       " 'IN',\n",
       " 'SOME',\n",
       " 'NOUN',\n",
       " 'PHRASES.',\n",
       " '',\n",
       " 'ENGLISH',\n",
       " 'GRAMMAR',\n",
       " 'REQUIRES',\n",
       " 'THAT',\n",
       " 'IN',\n",
       " 'MOST',\n",
       " 'CASES',\n",
       " 'A',\n",
       " 'NOUN',\n",
       " 'PHRASE',\n",
       " 'START',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'DETERMINER.',\n",
       " 'THE',\n",
       " 'MOST',\n",
       " 'COMMON',\n",
       " 'DETERMINERS',\n",
       " 'ARE',\n",
       " 'THE',\n",
       " 'ARTICLES',\n",
       " 'THE',\n",
       " 'AND',\n",
       " 'A(N),',\n",
       " 'WHICH',\n",
       " 'SPECIFY',\n",
       " 'THE',\n",
       " 'PRESENCE',\n",
       " 'OR',\n",
       " 'ABSENCE',\n",
       " 'OF',\n",
       " 'DEFINITENESS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'NOUN.',\n",
       " 'OTHER',\n",
       " 'POSSIBLE',\n",
       " 'DETERMINERS',\n",
       " 'INCLUDE',\n",
       " 'WORDS',\n",
       " 'LIKE',\n",
       " 'THIS,',\n",
       " 'MY,',\n",
       " 'EACH',\n",
       " 'AND',\n",
       " 'MANY',\n",
       " 'SEE',\n",
       " 'ENGLISH',\n",
       " 'DETERMINERS.',\n",
       " 'THERE',\n",
       " 'ARE',\n",
       " 'ALSO',\n",
       " 'CASES',\n",
       " 'WHERE',\n",
       " 'NO',\n",
       " 'DETERMINER',\n",
       " 'IS',\n",
       " 'REQUIRED,',\n",
       " 'AS',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SENTENCE',\n",
       " 'JOHN',\n",
       " 'LIKES',\n",
       " 'FAST',\n",
       " 'CARS,',\n",
       " 'WHERE',\n",
       " 'NEITHER',\n",
       " 'JOHN',\n",
       " 'NOR',\n",
       " 'FAST',\n",
       " 'CARS',\n",
       " 'INCLUDES',\n",
       " 'A',\n",
       " 'DETERMINER.',\n",
       " '']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/upper_test.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new text file that has lowercase letters\n",
    "file_upper = open(\"C:/Users/Dell/Downloads/upper_text.txt\",\"wt\")\n",
    "content = upper_rdd.reduce(lambda x,y: x+\" \"+y)\n",
    "file_upper.write(content)\n",
    "file_upper.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWrite a program to convert all words in a file to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "lower_rdd = rdd1.map(lambda word: word.lower())\n",
    "lower_rdd.collect()\n",
    "lower_rdd.saveAsTextFile(\"C:/Users/Dell/Downloads/lower_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'testing',\n",
       " 'text',\n",
       " 'file.',\n",
       " 'the',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'english',\n",
       " 'are',\n",
       " 'the',\n",
       " 'definite',\n",
       " 'article',\n",
       " 'the',\n",
       " 'and',\n",
       " 'the',\n",
       " 'indefinite',\n",
       " 'articles',\n",
       " 'a',\n",
       " 'and',\n",
       " 'an.',\n",
       " 'the',\n",
       " 'definite',\n",
       " 'article',\n",
       " 'is',\n",
       " 'used',\n",
       " 'when',\n",
       " 'the',\n",
       " 'speaker',\n",
       " 'believes',\n",
       " 'that',\n",
       " 'the',\n",
       " 'listener',\n",
       " 'knows',\n",
       " 'the',\n",
       " 'identity',\n",
       " 'of',\n",
       " 'the',\n",
       " \"noun's\",\n",
       " 'referent',\n",
       " '(because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'obvious,',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'common',\n",
       " 'knowledge,',\n",
       " 'or',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'mentioned',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'sentence',\n",
       " 'or',\n",
       " 'an',\n",
       " 'earlier',\n",
       " 'sentence).',\n",
       " 'the',\n",
       " 'indefinite',\n",
       " 'article',\n",
       " 'is',\n",
       " 'used',\n",
       " 'when',\n",
       " 'the',\n",
       " 'speaker',\n",
       " 'believes',\n",
       " 'that',\n",
       " 'the',\n",
       " 'listener',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'told',\n",
       " 'the',\n",
       " 'identity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'referent.',\n",
       " 'no',\n",
       " 'article',\n",
       " 'is',\n",
       " 'used',\n",
       " 'in',\n",
       " 'some',\n",
       " 'noun',\n",
       " 'phrases.',\n",
       " '',\n",
       " 'english',\n",
       " 'grammar',\n",
       " 'requires',\n",
       " 'that',\n",
       " 'in',\n",
       " 'most',\n",
       " 'cases',\n",
       " 'a',\n",
       " 'noun',\n",
       " 'phrase',\n",
       " 'start',\n",
       " 'with',\n",
       " 'a',\n",
       " 'determiner.',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'determiners',\n",
       " 'are',\n",
       " 'the',\n",
       " 'articles',\n",
       " 'the',\n",
       " 'and',\n",
       " 'a(n),',\n",
       " 'which',\n",
       " 'specify',\n",
       " 'the',\n",
       " 'presence',\n",
       " 'or',\n",
       " 'absence',\n",
       " 'of',\n",
       " 'definiteness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'noun.',\n",
       " 'other',\n",
       " 'possible',\n",
       " 'determiners',\n",
       " 'include',\n",
       " 'words',\n",
       " 'like',\n",
       " 'this,',\n",
       " 'my,',\n",
       " 'each',\n",
       " 'and',\n",
       " 'many',\n",
       " 'see',\n",
       " 'english',\n",
       " 'determiners.',\n",
       " 'there',\n",
       " 'are',\n",
       " 'also',\n",
       " 'cases',\n",
       " 'where',\n",
       " 'no',\n",
       " 'determiner',\n",
       " 'is',\n",
       " 'required,',\n",
       " 'as',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sentence',\n",
       " 'john',\n",
       " 'likes',\n",
       " 'fast',\n",
       " 'cars,',\n",
       " 'where',\n",
       " 'neither',\n",
       " 'john',\n",
       " 'nor',\n",
       " 'fast',\n",
       " 'cars',\n",
       " 'includes',\n",
       " 'a',\n",
       " 'determiner.',\n",
       " '']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/lower_test.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new text file that has lowercase letters\n",
    "file_lower = open(\"C:/Users/Dell/Downloads/lower_text.txt\",\"wt\")\n",
    "content = lower_rdd.reduce(lambda x,y: x+\" \"+y)\n",
    "file_lower.write(content)\n",
    "file_lower.close()\n",
    "#lower_rdd.reduce(lambda x,y: x+\" \"+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWrite a program to capitalize first letter of each words in file (use string capitalize() method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "caps_rdd = rdd1.map(lambda x: x.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Is',\n",
       " 'Just',\n",
       " 'A',\n",
       " 'Testing',\n",
       " 'Text',\n",
       " 'File.',\n",
       " 'The',\n",
       " 'Articles',\n",
       " 'In',\n",
       " 'English',\n",
       " 'Are',\n",
       " 'The',\n",
       " 'Definite',\n",
       " 'Article',\n",
       " 'The',\n",
       " 'And',\n",
       " 'The',\n",
       " 'Indefinite',\n",
       " 'Articles',\n",
       " 'A',\n",
       " 'And',\n",
       " 'An.',\n",
       " 'The',\n",
       " 'Definite',\n",
       " 'Article',\n",
       " 'Is',\n",
       " 'Used',\n",
       " 'When',\n",
       " 'The',\n",
       " 'Speaker',\n",
       " 'Believes',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Listener',\n",
       " 'Knows',\n",
       " 'The',\n",
       " 'Identity',\n",
       " 'Of',\n",
       " 'The',\n",
       " \"Noun's\",\n",
       " 'Referent',\n",
       " '(because',\n",
       " 'It',\n",
       " 'Is',\n",
       " 'Obvious,',\n",
       " 'Because',\n",
       " 'It',\n",
       " 'Is',\n",
       " 'Common',\n",
       " 'Knowledge,',\n",
       " 'Or',\n",
       " 'Because',\n",
       " 'It',\n",
       " 'Was',\n",
       " 'Mentioned',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Same',\n",
       " 'Sentence',\n",
       " 'Or',\n",
       " 'An',\n",
       " 'Earlier',\n",
       " 'Sentence).',\n",
       " 'The',\n",
       " 'Indefinite',\n",
       " 'Article',\n",
       " 'Is',\n",
       " 'Used',\n",
       " 'When',\n",
       " 'The',\n",
       " 'Speaker',\n",
       " 'Believes',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Listener',\n",
       " 'Does',\n",
       " 'Not',\n",
       " 'Have',\n",
       " 'To',\n",
       " 'Be',\n",
       " 'Told',\n",
       " 'The',\n",
       " 'Identity',\n",
       " 'Of',\n",
       " 'The',\n",
       " 'Referent.',\n",
       " 'No',\n",
       " 'Article',\n",
       " 'Is',\n",
       " 'Used',\n",
       " 'In',\n",
       " 'Some',\n",
       " 'Noun',\n",
       " 'Phrases.',\n",
       " '',\n",
       " 'English',\n",
       " 'Grammar',\n",
       " 'Requires',\n",
       " 'That',\n",
       " 'In',\n",
       " 'Most',\n",
       " 'Cases',\n",
       " 'A',\n",
       " 'Noun',\n",
       " 'Phrase',\n",
       " 'Start',\n",
       " 'With',\n",
       " 'A',\n",
       " 'Determiner.',\n",
       " 'The',\n",
       " 'Most',\n",
       " 'Common',\n",
       " 'Determiners',\n",
       " 'Are',\n",
       " 'The',\n",
       " 'Articles',\n",
       " 'The',\n",
       " 'And',\n",
       " 'A(n),',\n",
       " 'Which',\n",
       " 'Specify',\n",
       " 'The',\n",
       " 'Presence',\n",
       " 'Or',\n",
       " 'Absence',\n",
       " 'Of',\n",
       " 'Definiteness',\n",
       " 'Of',\n",
       " 'The',\n",
       " 'Noun.',\n",
       " 'Other',\n",
       " 'Possible',\n",
       " 'Determiners',\n",
       " 'Include',\n",
       " 'Words',\n",
       " 'Like',\n",
       " 'This,',\n",
       " 'My,',\n",
       " 'Each',\n",
       " 'And',\n",
       " 'Many',\n",
       " 'See',\n",
       " 'English',\n",
       " 'Determiners.',\n",
       " 'There',\n",
       " 'Are',\n",
       " 'Also',\n",
       " 'Cases',\n",
       " 'Where',\n",
       " 'No',\n",
       " 'Determiner',\n",
       " 'Is',\n",
       " 'Required,',\n",
       " 'As',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Sentence',\n",
       " 'John',\n",
       " 'Likes',\n",
       " 'Fast',\n",
       " 'Cars,',\n",
       " 'Where',\n",
       " 'Neither',\n",
       " 'John',\n",
       " 'Nor',\n",
       " 'Fast',\n",
       " 'Cars',\n",
       " 'Includes',\n",
       " 'A',\n",
       " 'Determiner.',\n",
       " '']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Is',\n",
       " 'Just',\n",
       " 'A',\n",
       " 'Testing',\n",
       " 'Text',\n",
       " 'File.',\n",
       " 'The',\n",
       " 'Articles',\n",
       " 'In',\n",
       " 'English',\n",
       " 'Are',\n",
       " 'The',\n",
       " 'Definite',\n",
       " 'Article',\n",
       " 'The',\n",
       " 'And',\n",
       " 'The',\n",
       " 'Indefinite',\n",
       " 'Articles',\n",
       " 'A',\n",
       " 'And',\n",
       " 'An.',\n",
       " 'The',\n",
       " 'Definite',\n",
       " 'Article',\n",
       " 'Is',\n",
       " 'Used',\n",
       " 'When',\n",
       " 'The',\n",
       " 'Speaker',\n",
       " 'Believes',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Listener',\n",
       " 'Knows',\n",
       " 'The',\n",
       " 'Identity',\n",
       " 'Of',\n",
       " 'The',\n",
       " \"Noun's\",\n",
       " 'Referent',\n",
       " '(because',\n",
       " 'It',\n",
       " 'Is',\n",
       " 'Obvious,',\n",
       " 'Because',\n",
       " 'It',\n",
       " 'Is',\n",
       " 'Common',\n",
       " 'Knowledge,',\n",
       " 'Or',\n",
       " 'Because',\n",
       " 'It',\n",
       " 'Was',\n",
       " 'Mentioned',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Same',\n",
       " 'Sentence',\n",
       " 'Or',\n",
       " 'An',\n",
       " 'Earlier',\n",
       " 'Sentence).',\n",
       " 'The',\n",
       " 'Indefinite',\n",
       " 'Article',\n",
       " 'Is',\n",
       " 'Used',\n",
       " 'When',\n",
       " 'The',\n",
       " 'Speaker',\n",
       " 'Believes',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Listener',\n",
       " 'Does',\n",
       " 'Not',\n",
       " 'Have',\n",
       " 'To',\n",
       " 'Be',\n",
       " 'Told',\n",
       " 'The',\n",
       " 'Identity',\n",
       " 'Of',\n",
       " 'The',\n",
       " 'Referent.',\n",
       " 'No',\n",
       " 'Article',\n",
       " 'Is',\n",
       " 'Used',\n",
       " 'In',\n",
       " 'Some',\n",
       " 'Noun',\n",
       " 'Phrases.',\n",
       " '',\n",
       " 'English',\n",
       " 'Grammar',\n",
       " 'Requires',\n",
       " 'That',\n",
       " 'In',\n",
       " 'Most',\n",
       " 'Cases',\n",
       " 'A',\n",
       " 'Noun',\n",
       " 'Phrase',\n",
       " 'Start',\n",
       " 'With',\n",
       " 'A',\n",
       " 'Determiner.',\n",
       " 'The',\n",
       " 'Most',\n",
       " 'Common',\n",
       " 'Determiners',\n",
       " 'Are',\n",
       " 'The',\n",
       " 'Articles',\n",
       " 'The',\n",
       " 'And',\n",
       " 'A(n),',\n",
       " 'Which',\n",
       " 'Specify',\n",
       " 'The',\n",
       " 'Presence',\n",
       " 'Or',\n",
       " 'Absence',\n",
       " 'Of',\n",
       " 'Definiteness',\n",
       " 'Of',\n",
       " 'The',\n",
       " 'Noun.',\n",
       " 'Other',\n",
       " 'Possible',\n",
       " 'Determiners',\n",
       " 'Include',\n",
       " 'Words',\n",
       " 'Like',\n",
       " 'This,',\n",
       " 'My,',\n",
       " 'Each',\n",
       " 'And',\n",
       " 'Many',\n",
       " 'See',\n",
       " 'English',\n",
       " 'Determiners.',\n",
       " 'There',\n",
       " 'Are',\n",
       " 'Also',\n",
       " 'Cases',\n",
       " 'Where',\n",
       " 'No',\n",
       " 'Determiner',\n",
       " 'Is',\n",
       " 'Required,',\n",
       " 'As',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Sentence',\n",
       " 'John',\n",
       " 'Likes',\n",
       " 'Fast',\n",
       " 'Cars,',\n",
       " 'Where',\n",
       " 'Neither',\n",
       " 'John',\n",
       " 'Nor',\n",
       " 'Fast',\n",
       " 'Cars',\n",
       " 'Includes',\n",
       " 'A',\n",
       " 'Determiner.',\n",
       " '']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving rdd into a file\n",
    "caps_rdd.saveAsTextFile(\"C:/Users/Dell/Downloads/caps.txt\")\n",
    "rdd = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/caps.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(\"C:/Users/Dell/Downloads/caps_view.txt\",\"wt\")\n",
    "content = caps_rdd.reduce(lambda x,y: x+\" \"+y)\n",
    "file.write(content)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tFind the longest length of word from given set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'just', 'a', 'testing']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/test.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "rdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest(l,r):\n",
    "    if len(l)>len(r):\n",
    "        return l\n",
    "    else:\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'determiner.[1]'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.reduce(lambda x,y: longest(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tMap the Registration numbers to corresponding branch. 6000 series BDA, 9000 series HAD, 1000 series MS, 2000 series VLSI, 3000 series ES, 4000 series MSc, 5000 series CC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollnum_rdd = Spark.sparkContext.parallelize((1427,3457,9876,2314,1771,1345,2985,2765,2323,4111,4561,5681,5966,6723,6887,6001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_regnum(regnum):\n",
    "    if regnum>=9000:\n",
    "        return 'HAD'\n",
    "    elif regnum>=6000:\n",
    "        return 'BDA'\n",
    "    elif regnum>=5000:\n",
    "        return 'CC'\n",
    "    elif regnum>4000:\n",
    "        return 'MSc'\n",
    "    elif regnum>=3000:\n",
    "        return 'ES'\n",
    "    elif regnum>=2000:\n",
    "        return 'VLSI'\n",
    "    elif regnum>=1000:\n",
    "        return 'MS'\n",
    "    else:\n",
    "        return 'Invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS',\n",
       " 'ES',\n",
       " 'HAD',\n",
       " 'VLSI',\n",
       " 'MS',\n",
       " 'MS',\n",
       " 'VLSI',\n",
       " 'VLSI',\n",
       " 'VLSI',\n",
       " 'MSc',\n",
       " 'MSc',\n",
       " 'CC',\n",
       " 'CC',\n",
       " 'BDA',\n",
       " 'BDA',\n",
       " 'BDA']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_rdd = rollnum_rdd.map(lambda rollnum:map_regnum(rollnum))\n",
    "branch_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tGiven registration number, generate a key-value pair of Registration Number and Corresponding Branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1427, 'MS'),\n",
       " (3457, 'ES'),\n",
       " (9876, 'HAD'),\n",
       " (2314, 'VLSI'),\n",
       " (1771, 'MS'),\n",
       " (1345, 'MS'),\n",
       " (2985, 'VLSI'),\n",
       " (2765, 'VLSI'),\n",
       " (2323, 'VLSI'),\n",
       " (4111, 'MSc'),\n",
       " (4561, 'MSc'),\n",
       " (5681, 'CC'),\n",
       " (5966, 'CC'),\n",
       " (6723, 'BDA'),\n",
       " (6887, 'BDA'),\n",
       " (6001, 'BDA')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_rdd = rollnum_rdd.map(lambda rollnum: (rollnum,map_regnum(rollnum)))\n",
    "branch_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tA text file contains data about citizens of country. Fields(information in file) are Name, dob, Phone, email and state name. Another file contains mapping of state names to state code like Karnataka is codes as KA, TamilNadu as TN, Kerala KL etc. Compress the file will by changing full state name to state code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['personA', '03-09-2010', '2345671872', 'personA@gmail.com', 'Karnataka'],\n",
       " ['personB', '23-12-1980', '6782081736', 'personB@gmail.com', 'Maharashtra'],\n",
       " ['personC', '07-11-1999', '6391376182', 'personC@gmail.com', 'Jharkhand'],\n",
       " ['personD',\n",
       "  '29-03-1955',\n",
       "  '9871367281',\n",
       "  'personD@gmail.com',\n",
       "  'Andhra Pradesh']]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading citizendata\n",
    "citizen_rdd = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/citizens_data.txt\", minPartitions=4).map(lambda ele:ele.split(\",\"))\n",
    "citizen_rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Andaman and Nicobar Islands', 'AN'], ['Andhra Pradesh', 'AP']]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading states and state codes\n",
    "states_rdd = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/state_code.txt\", minPartitions=4).map(lambda ele:ele.split(\"\\t\"))\n",
    "states_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('personA', ('03-09-2010', None)),\n",
       " ('personB', ('23-12-1980', None)),\n",
       " ('personC', ('07-11-1999', None)),\n",
       " ('personD', ('29-03-1955', None))]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#citizen_rdd.map(lambda x:(x[4])).leftOuterJoin(states_rdd.map(lambda y:(y[0],y[1]))).collect()\n",
    "citizen_rdd.leftOuterJoin(states_rdd).collect()\n",
    "#newRdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Andaman and Nicobar Islands', 'AN'),\n",
       " ('Andhra Pradesh', 'AP'),\n",
       " ('Arunachal Pradesh', 'AR'),\n",
       " ('Assam', 'AS'),\n",
       " ('Bihar', 'BR'),\n",
       " ('Chandigarh', 'CH'),\n",
       " ('Chhattisgarh', 'CT'),\n",
       " ('Dadra and Nagar Haveli', 'DN'),\n",
       " ('Daman and Diu', 'DD'),\n",
       " ('Delhi', 'DL'),\n",
       " ('Goa', 'GA'),\n",
       " ('Gujarat', 'GJ'),\n",
       " ('Haryana', 'HR'),\n",
       " ('Himachal Pradesh', 'HP'),\n",
       " ('Jammu and Kashmir', 'JK'),\n",
       " ('Jharkhand', 'JH'),\n",
       " ('Karnataka', 'KA'),\n",
       " ('Kerala', 'KL'),\n",
       " ('Lakshadweep', 'LD'),\n",
       " ('Madhya Pradesh', 'MP'),\n",
       " ('Maharashtra', 'MH'),\n",
       " ('Manipur', 'MN'),\n",
       " ('Meghalaya', 'ML'),\n",
       " ('Mizoram', 'MZ'),\n",
       " ('Nagaland', 'NL'),\n",
       " ('Odisha', 'OR'),\n",
       " ('Puducherry', 'PY'),\n",
       " ('Punjab', 'PB'),\n",
       " ('Rajasthan', 'RJ'),\n",
       " ('Sikkim', 'SK'),\n",
       " ('Tamil Nadu', 'TN'),\n",
       " ('Telangana', 'TG'),\n",
       " ('Tripura', 'TR'),\n",
       " ('Uttar Pradesh', 'UP'),\n",
       " ('Uttarakhand', 'UT'),\n",
       " ('West Bengal', 'WB')]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_rdd.map(lambda x:(x[0],(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.\tText file contain numbers. Numbers are separated by one white space. There is no order to store the numbers. One line may contain one or more numbers. Find the maximum, minimum, sum and mean of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading the file\n",
    "nums_rdd = Spark.sparkContext.textFile(\"C:/Users/Dell/Downloads/numbers.txt\", minPartitions=4).flatMap(lambda ele:ele.split(\" \"))\n",
    "nums_rdd_converted=nums_rdd.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sum\n",
    "nums_sum=nums_rdd_converted.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "845"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum of numbers\n",
    "nums_rdd_converted.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum of the numbers\n",
    "nums_rdd_converted.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.5909090909091"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting average\n",
    "nums_count = nums_rdd_converted.count()\n",
    "nums_sum/nums_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
